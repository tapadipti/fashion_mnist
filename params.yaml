train:
  batch_size: 128
  hidden_units: 128
  dropout: 0.40
  num_epochs: 10
  lr: 0.01
  conv_activation: relu
